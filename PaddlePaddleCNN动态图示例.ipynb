{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-14 11:05:27,060-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-07-14 11:05:27,412-INFO: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import paddle\n",
    "import matplotlib.pyplot as plt#用于绘图\n",
    "from PIL import Image#用于绘图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "查看MNIST数据样例，仅用一张图做展示\n",
    "（代码无需掌握，仅需对数据集有所了解）\n",
    "\n",
    "MNIST是一个手写数字数据库，它有60000个训练样本集和10000个测试样本集。它是NIST数据库的一个子集。\n",
    "\n",
    "         MNIST数据库官方网址为：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/) ，也可以在windows下直接下载，train-images-idx3-ubyte.gz、train-labels-idx1-ubyte.gz等。下载四个文件，解压缩。解压缩后发现这些文件并不是标准的图像格式。这些图像数据都保存在二进制文件中。每个样本图像的宽高为28*28。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_reader = paddle.batch(paddle.dataset.mnist.train(), batch_size=1)#仅加载第一张图\n",
    "temp_data=next(temp_reader())#加载一张图\n",
    "temp_data = np.reshape(temp_data[0][0],[28,28])#将list格式的数据转化为28*28\n",
    "image1 = temp_data.astype(\"uint8\")#设置图片数据格式为无符号整数\n",
    "img = Image.fromarray(image1)#将矩阵转化为图片格式\n",
    "plt.imshow(img)#设置图片\n",
    "plt.show()#展示图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fluid的字面意思是流动、流体，意思和tensorflow的flow有点意思，都暗指数据流流动。\n",
    "\n",
    "Fluid和Tensorflow最大的区别是Fluid把模型定义为由多个程序块组成的程序，每个程序块完成一系列计算。\n",
    "\n",
    "而Tensorflow将模型定义为一张计算图，图中每一部分是数据的流向与计算。Fluid从程序员的视角和习惯来设计，Tensorflow更倾向于数据科学者的视角。\n",
    "\n",
    "知乎上一篇文章对此的介绍不错：[PaddleFluid和TensorFlow基本使用概念对比](https://zhuanlan.zhihu.com/p/38290380)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "下面的实例展示了一个卷积神经网络的定义方式\n",
    "\n",
    "一个CNN模型被定义为一个类。这个类里面包含两个函数：_init_和forword\n",
    "\n",
    "首先_init_ 函数定义了模型的各层，相当于Tensorflow计算图中的各个节点。\n",
    "\n",
    "而forward函数则定义了各层之间的连结方式，也就是张量的流动方向。之所以叫forward，是因为这也是神经网络中数据前向传播的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这个简单的CNN网络仅包含两个卷积层和两个池化层。\n",
    "\n",
    "我们先在_init_中定义各层。\n",
    "\n",
    "> self.conv1 = Conv2D(num_channels=1, num_filters=32, filter_size=3, act='sigmoid')\n",
    "\n",
    "num_channels表示输入数据的通道数（数据经过几个卷积核/filter，就有多少通道数）。由于我们这是第一个卷积层，还没经历过filter，所以channel数为1。\n",
    "\n",
    "然后我们这一层使用32个卷积核filter，卷积核尺寸3\\*3，激活函数sigmoid。卷积核数和卷积核尺寸不是不是唯一，可以自己调整，我们只是展示一个尝试了很多次后得到的一个比较好的参数。\n",
    "\n",
    "经过第一个卷积层后，图片的尺寸从28\\*28转为26\\*26（28-3+1）\\*32。\n",
    "\n",
    "然后我们再定义一个池化层：\n",
    "\n",
    "> self.pool1 = Pool2D(pool_size=2, pool_stride=1, pool_type='max')\n",
    "\n",
    "pool_size=2表示池化层降采样的核使用的尺寸是2\\*2，pool_stride=1表示每次降采样后向旁边滑动一个像素。pool_type='max'表示降采样的方式是取2\\*2区域中的最大值。例如[254,231,153,142]经过降采样后只保留一个数字254。经过这层后数据的尺寸为25\\*25\\*32。25=26/1-2+1。\n",
    "\n",
    "经过第二个卷积核后，数据尺寸为23\\*23（25-3+1）\\*64。\n",
    "\n",
    "经过第二个池化层后，数据尺寸为22\\*22（23/1-2+1）\\*64。转为一维的话是30976\\*1。\n",
    "\n",
    "最后一层是全连层，全连层的输入不是矩阵，而是一个序列，是一维的。所以要把之前的张量转为一维数据。\n",
    "> self.fc1 = Linear(input_dim=30976, output_dim=num_classes)\n",
    "\n",
    "30976根据上面计算得出，num_classes是手写体数字的种类，从0到9，十种。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "第二个函数是forward函数，要把各层连结起来。这个很像Keras的Model形式。\n",
    "\n",
    ">注意 x = fluid.layers.reshape(x, [x.shape[0], -1])这一行。\n",
    "\n",
    "这里进行reshape操作是因为pool2层的输出是22\\*22\\*64，而全连层要求的输入是一维的，所以要把矩阵reshape成一维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "# 定义 CNN 网络结构\n",
    "class CNN(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=1, num_filters=32, filter_size=3, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=1, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=32, num_filters=64, filter_size=3, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=1, pool_type='max')\n",
    "        self.fc1 = Linear(input_dim=30976, output_dim=num_classes)\n",
    "\n",
    "    # 网络的前向计算过程\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "后面就是训练过程，这个过程比较流程化，在其他项目中比较好迁移。\n",
    "\n",
    ">  with fluid.dygraph.guard():\n",
    "\n",
    "表示后面使用动态图\n",
    "\n",
    "> model = CNN(num_classes=10)\n",
    "定义模型\n",
    "\n",
    "> train(model)\n",
    " 启动训练过程\n",
    "\n",
    "> epoch_num = 12\n",
    "表示训练12轮，大家可以自己加减看效果\n",
    "\n",
    "> opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "\n",
    "这里学习率为0.001，动量为0.9（用于跳出局部最小值）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=10)\n",
    "valid_loader = paddle.batch(paddle.dataset.mnist.test(), batch_size=10)\n",
    "\n",
    "加载数据\n",
    "\n",
    "> loss = fluid.layers.softmax_with_cross_entropy(logits, label)\n",
    "\n",
    "定义损失函数为交叉熵函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [2.7852263]\n",
      "epoch: 0, batch_id: 1000, loss is: [0.10298177]\n",
      "epoch: 0, batch_id: 2000, loss is: [0.2644323]\n",
      "epoch: 0, batch_id: 3000, loss is: [0.01399288]\n",
      "epoch: 0, batch_id: 4000, loss is: [0.03530569]\n",
      "epoch: 0, batch_id: 5000, loss is: [0.15203491]\n",
      "[validation] accuracy/loss: 0.929900050163269/0.23405927419662476\n",
      "epoch: 1, batch_id: 0, loss is: [0.05236039]\n",
      "epoch: 1, batch_id: 1000, loss is: [0.02579585]\n",
      "epoch: 1, batch_id: 2000, loss is: [0.02599655]\n",
      "epoch: 1, batch_id: 3000, loss is: [0.00830223]\n",
      "epoch: 1, batch_id: 4000, loss is: [0.01651256]\n",
      "epoch: 1, batch_id: 5000, loss is: [0.04333802]\n",
      "[validation] accuracy/loss: 0.9601999521255493/0.12818966805934906\n",
      "epoch: 2, batch_id: 0, loss is: [0.02193589]\n",
      "epoch: 2, batch_id: 1000, loss is: [0.0117144]\n",
      "epoch: 2, batch_id: 2000, loss is: [0.01779418]\n",
      "epoch: 2, batch_id: 3000, loss is: [0.02125602]\n",
      "epoch: 2, batch_id: 4000, loss is: [0.01673141]\n",
      "epoch: 2, batch_id: 5000, loss is: [0.01332028]\n",
      "[validation] accuracy/loss: 0.9721999764442444/0.09072727710008621\n",
      "epoch: 3, batch_id: 0, loss is: [0.01443294]\n",
      "epoch: 3, batch_id: 1000, loss is: [0.01247411]\n",
      "epoch: 3, batch_id: 2000, loss is: [0.01709996]\n",
      "epoch: 3, batch_id: 3000, loss is: [0.02566863]\n",
      "epoch: 3, batch_id: 4000, loss is: [0.01651136]\n",
      "epoch: 3, batch_id: 5000, loss is: [0.00600322]\n",
      "[validation] accuracy/loss: 0.9767999053001404/0.07436449080705643\n",
      "epoch: 4, batch_id: 0, loss is: [0.01232123]\n",
      "epoch: 4, batch_id: 1000, loss is: [0.00916539]\n",
      "epoch: 4, batch_id: 2000, loss is: [0.01655547]\n",
      "epoch: 4, batch_id: 3000, loss is: [0.0174532]\n",
      "epoch: 4, batch_id: 4000, loss is: [0.01696749]\n",
      "epoch: 4, batch_id: 5000, loss is: [0.00364634]\n",
      "[validation] accuracy/loss: 0.9785999655723572/0.06596937030553818\n",
      "epoch: 5, batch_id: 0, loss is: [0.01031789]\n",
      "epoch: 5, batch_id: 1000, loss is: [0.00679124]\n",
      "epoch: 5, batch_id: 2000, loss is: [0.01558154]\n",
      "epoch: 5, batch_id: 3000, loss is: [0.00996216]\n",
      "epoch: 5, batch_id: 4000, loss is: [0.01796303]\n",
      "epoch: 5, batch_id: 5000, loss is: [0.00253832]\n",
      "[validation] accuracy/loss: 0.9794999957084656/0.061482153832912445\n",
      "epoch: 6, batch_id: 0, loss is: [0.00730656]\n",
      "epoch: 6, batch_id: 1000, loss is: [0.00559701]\n",
      "epoch: 6, batch_id: 2000, loss is: [0.01404848]\n",
      "epoch: 6, batch_id: 3000, loss is: [0.00586601]\n",
      "epoch: 6, batch_id: 4000, loss is: [0.01891478]\n",
      "epoch: 6, batch_id: 5000, loss is: [0.00185323]\n",
      "[validation] accuracy/loss: 0.9803999662399292/0.058832887560129166\n",
      "epoch: 7, batch_id: 0, loss is: [0.00465131]\n",
      "epoch: 7, batch_id: 1000, loss is: [0.00483529]\n",
      "epoch: 7, batch_id: 2000, loss is: [0.01232703]\n",
      "epoch: 7, batch_id: 3000, loss is: [0.00381579]\n",
      "epoch: 7, batch_id: 4000, loss is: [0.01967024]\n",
      "epoch: 7, batch_id: 5000, loss is: [0.00139869]\n",
      "[validation] accuracy/loss: 0.9805999994277954/0.0570378415286541\n",
      "epoch: 8, batch_id: 0, loss is: [0.0030043]\n",
      "epoch: 8, batch_id: 1000, loss is: [0.00429296]\n",
      "epoch: 8, batch_id: 2000, loss is: [0.01078828]\n",
      "epoch: 8, batch_id: 3000, loss is: [0.00273515]\n",
      "epoch: 8, batch_id: 4000, loss is: [0.02022543]\n",
      "epoch: 8, batch_id: 5000, loss is: [0.0010962]\n",
      "[validation] accuracy/loss: 0.9812999963760376/0.055636242032051086\n",
      "epoch: 9, batch_id: 0, loss is: [0.00208247]\n",
      "epoch: 9, batch_id: 1000, loss is: [0.00390938]\n",
      "epoch: 9, batch_id: 2000, loss is: [0.00956237]\n",
      "epoch: 9, batch_id: 3000, loss is: [0.00210936]\n",
      "epoch: 9, batch_id: 4000, loss is: [0.02066088]\n",
      "epoch: 9, batch_id: 5000, loss is: [0.00089123]\n",
      "[validation] accuracy/loss: 0.9814999103546143/0.05442054569721222\n",
      "epoch: 10, batch_id: 0, loss is: [0.00156979]\n",
      "epoch: 10, batch_id: 1000, loss is: [0.00365227]\n",
      "epoch: 10, batch_id: 2000, loss is: [0.00864409]\n",
      "epoch: 10, batch_id: 3000, loss is: [0.00171322]\n",
      "epoch: 10, batch_id: 4000, loss is: [0.02096837]\n",
      "epoch: 10, batch_id: 5000, loss is: [0.00074668]\n",
      "[validation] accuracy/loss: 0.9815999865531921/0.053289562463760376\n",
      "epoch: 11, batch_id: 0, loss is: [0.00127622]\n",
      "epoch: 11, batch_id: 1000, loss is: [0.0034946]\n",
      "epoch: 11, batch_id: 2000, loss is: [0.00797538]\n",
      "epoch: 11, batch_id: 3000, loss is: [0.00144061]\n",
      "epoch: 11, batch_id: 4000, loss is: [0.0211457]\n",
      "epoch: 11, batch_id: 5000, loss is: [0.00064048]\n",
      "[validation] accuracy/loss: 0.9816999435424805/0.05221845582127571\n"
     ]
    }
   ],
   "source": [
    "# 定义训练过程\n",
    "def train(model):\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "    epoch_num = 12\n",
    "    opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "    # 使用Paddle自带的数据读取器\n",
    "    train_loader = paddle.batch(paddle.dataset.mnist.train(), batch_size=10)\n",
    "    valid_loader = paddle.batch(paddle.dataset.mnist.test(), batch_size=10)\n",
    "    for epoch in range(epoch_num):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            # 调整输入数据形状和类型\n",
    "            x_data = np.array([item[0] for item in data], dtype='float32').reshape(-1, 1, 28, 28)\n",
    "            y_data = np.array([item[1] for item in data], dtype='int64').reshape(-1, 1)\n",
    "            # 将numpy.ndarray转化成Tensor\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            # 计算损失函数\n",
    "            loss = fluid.layers.softmax_with_cross_entropy(logits, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "            avg_loss.backward()\n",
    "            opt.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(valid_loader()):\n",
    "            # 调整输入数据形状和类型\n",
    "            x_data = np.array([item[0] for item in data], dtype='float32').reshape(-1, 1, 28, 28)\n",
    "            y_data = np.array([item[1] for item in data], dtype='int64').reshape(-1, 1)\n",
    "            # 将numpy.ndarray转化成Tensor\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算模型输出\n",
    "            logits = model(img)\n",
    "            pred = fluid.layers.softmax(logits)\n",
    "            # 计算损失函数\n",
    "            loss = fluid.layers.softmax_with_cross_entropy(logits, label)\n",
    "            acc = fluid.layers.accuracy(pred, label)\n",
    "            accuracies.append(acc.numpy())\n",
    "            losses.append(loss.numpy())\n",
    "        print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "        model.train()\n",
    "\n",
    "    # 保存模型参数\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 创建模型\n",
    "    with fluid.dygraph.guard():\n",
    "        model = CNN(num_classes=10)\n",
    "        #启动训练过程\n",
    "        train(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
